# GPT-2 Demo

A two-part demonstration of GPT-2 as a creative tool:

1. A [twitter bot](https://twitter.com/tweetForThat1) trained on over 28,000 tweets from the @realDonaldTrump Twitter Account. Still under development. 
2. A [companion podcast](https://soundcloud.com/user-545533369/on-computational-creative-assists) where three Columbia University experts and I tackle GPT-2 as a creative assists for artists. We discuss the origins of mathematic-induced inspiration and dissect the output of GPT-2 on air.      
 
## Ingredients:

* [GPT-2](https://openai.com/blog/better-language-models/)
* [GPT-2-simple](https://github.com/minimaxir/gpt-2-simple)
* [Google colab](https://colab.research.google.com/)
* [Tweepy](https://www.tweepy.org/)
 
 
## Show notes

When Open AI, a Silicon Valley non-profit released the GPT-2, they made some suggestions about its potential uses. One was to create an unstoppable army of talkative robots to drive discourse on the internet and destroy the world.

Another was to serve as a writing assistant – to help people overcome writer’s block.

We unpack the later with three Columbia University experts: Chris Kedzie and Katy Gero, PhD candidates from the computer science departments, and Sophie Brett-Chin, who's earning an MFA concentraiting in creative non-fiction.


* [Intro script](https://github.com/aaronbrezel/GPT-2_Demo/blob/master/Podcast/intro_script.md) 
* [Sample outputs](https://github.com/aaronbrezel/GPT-2_Demo/blob/master/Podcast/Sample_Outputs.md)




Current steps:

1. Used https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce as guide for training of both sophie's model and the donald trump tweets model. Unfortunately, I do not have a GPU.  
2. Downloaded text of all of trumps tweets as of 5:30 p.m. 11/26/19 from the [Trump Twitter Archive](http://www.trumptwitterarchive.com/archive). Tweet text was edited to remove retweets and and outbound links
3. 

## Twitter bot notes


## Credit: 

All GPT-2 training for this demo was performed on a Python 3 Google Colab notebook using the [GPT-2-simple](https://github.com/minimaxir/gpt-2-simple) library developed by [Max Woolf](https://minimaxir.com/). If you like what I did here, Max made it possible. So, consider donating to his [Patreon](https://www.patreon.com/minimaxir) so he can help people make more cool stuff. 
